---
title: "Benchmark gallery"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Benchmark gallery}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 4
)
```

## What’s in here

- Benchmarks of the core methods (snic, slice_msf, supervoxels, flash3d, rena, acsc)
- Shared synthetic datasets of increasing size/complexity
- A few common parameter settings per method to show how runtime and cluster count move

The heavy lifting is done by `inst/benchmarks/bench_methods.R`. We keep that **off by default** so the vignette stays light; instead we read precomputed results if they exist.

## How to reproduce locally

```r
# from the package root
Rscript inst/benchmarks/bench_methods.R
```

This writes `inst/benchmarks/results.csv`. Re-knit this vignette to refresh the tables/plots.

## Load results (if available)

```{r load-results}
res_path <- system.file("benchmarks/results.csv", package = "neurocluster")
if (!file.exists(res_path)) {
  cat("Benchmark results not found. Run inst/benchmarks/bench_methods.R to generate them.")
  has_results <- FALSE
} else {
  results <- read.csv(res_path, stringsAsFactors = FALSE)
  results$elapsed_sec <- as.numeric(results$elapsed_sec)
  has_results <- TRUE
}
```

## Summary table

```{r table, echo=FALSE}
if (has_results) head(results, 12)
```

## Quick plots

```{r plots, echo=FALSE, message=FALSE, warning=FALSE}
if (has_results && requireNamespace("ggplot2", quietly = TRUE)) {
  library(ggplot2)
  results$method <- factor(results$method, levels = sort(unique(results$method)))

  # Best ARI per method/dataset (show param_id to avoid "cherry-pick" concerns)
  if (!all(is.na(results$ari))) {
    best_ari <- subset(results, !is.na(ari))
    best_ari <- best_ari[order(best_ari$dataset, best_ari$method, -best_ari$ari), ]
    best_ari <- best_ari[!duplicated(best_ari[c("dataset","method")]), ]
    p_best_ari <- ggplot(best_ari, aes(x = method, y = ari, fill = dataset, alpha = factor(param_id))) +
      geom_col(position = position_dodge()) +
      scale_alpha_discrete(name = "param_id") +
      scale_y_continuous("Best ARI (per method/dataset)", limits = c(0, 1)) +
      coord_flip() +
      theme_minimal()
    print(p_best_ari)
  }

  p_time <- ggplot(results, aes(x = method, y = elapsed_sec, fill = dataset)) +
    geom_col(position = position_dodge()) +
    scale_y_log10("Elapsed (s, log scale)", limits = c(min(results$elapsed_sec[results$elapsed_sec>0])*0.8, NA)) +
    coord_flip() +
    theme_minimal()

  p_k <- ggplot(results, aes(x = method, y = n_clusters, fill = dataset)) +
    geom_col(position = position_dodge()) +
    scale_y_continuous("Clusters found", limits = c(0, NA)) +
    coord_flip() +
    theme_minimal()

  # Relative time within each dataset (faster to compare)
  rel <- results
  rel <- rel[rel$elapsed_sec > 0, ]
  rel$rel_time <- ave(rel$elapsed_sec, rel$dataset, FUN = function(x) x / min(x))
  p_rel <- ggplot(rel, aes(x = method, y = rel_time, fill = dataset)) +
    geom_col(position = position_dodge()) +
    scale_y_log10("Relative time (vs fastest in dataset, log scale)", limits = c(1, NA)) +
    coord_flip() +
    theme_minimal()

  # Accuracy (if available)
  acc <- results[!is.na(results$ari), ]
  if (nrow(acc) > 0) {
    p_ari <- ggplot(acc, aes(x = method, y = ari, fill = dataset, alpha = factor(param_id))) +
      geom_col(position = position_dodge()) +
      scale_alpha_discrete(name = "param_id") +
      scale_y_continuous("Adjusted Rand Index", limits = c(0, 1)) +
      coord_flip() +
      theme_minimal()
    print(p_ari)
  }

  print(p_time)
  print(p_rel)
  print(p_k)
}
```

## Notes on parameters

- **snic**: compactness = {2, 5}
- **slice_msf**: r = {8, 12}, min_size tuned for small/medium data
- **supervoxels**: alpha = {0.4, 0.8}
- **flash3d**: dctM = {8, 12}
- **rena**: connectivity = {6, 26}
- **acsc**: lambda = {0.6, 1.0}

These are not exhaustive sweeps—just representative settings to show trends without long runtimes. Adjust `inst/benchmarks/bench_methods.R` if you want deeper dives.
